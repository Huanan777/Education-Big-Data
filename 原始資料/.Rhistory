統
計
comparison <- cbind(stats_data1, stats_data2)
rownames(comparison) <- common_vars  #
設
置
變
數
名
稱
為
行
索
引
colnames(comparison) <- c("Mean_data1", "SD_data1", "Min_data1", "Max_data1",
"Mean_data2", "SD_data2", "Min_data2", "Max_data2")
#
查
看
合
併
結
果
print(comparison)
#
匯
出
敘
述
統
計
到 Excel
if (!require("writexl")) {
install.packages("writexl")
}
library(writexl)
write_xlsx(comparison, "comparison_stats.xlsx")
cat("
敘
述
統
計
已
成
功
匯
出
至
檔
案: comparison_stats.xlsx\n")
#
將
行
名
稱 (
變
數
名
稱)
轉
換
為
資
料
框
中
的
獨
立
欄
位
comparison <- cbind(Variable = rownames(comparison), comparison)
rownames(comparison) <- NULL  #
移
除
行
名
稱
，
避
免
干
擾
#
使
用 writexl
匯
出
if (!require("writexl")) {
install.packages("writexl")
}
library(writexl)
#
匯
出
包
含
變
數
名
稱
的
資
料
到 Excel
write_xlsx(comparison, "comparison_stats_with_variables.xlsx")
cat("
敘
述
統
計
已
成
功
匯
出
至
檔
案: comparison_stats_with_variables.xlsx\n")
q()
# 安裝必要套件
install.packages("psych")
install.packages("GPArotation")
library(psych)
# 載入資料
data1 <- read.csv("data_1.csv", stringsAsFactors = FALSE)
library(psych)
# 載入資料
data1 <- read.csv("data_1.csv", stringsAsFactors = FALSE)
library(psych)
# 載入資料
data1 <- read.csv("data_1.csv", stringsAsFactors = FALSE)
setwd("C:\\Users\\huann\\OneDrive\\Desktop\\Education Big Data\\原始資料")
library(psych)
# 載入資料
data1 <- read.csv("data_1.csv", stringsAsFactors = FALSE)
# 篩選題目欄位 v1~v60
data_items <- data1[, grep("^v[0-9]+$", names(data1))]
# 去除 NA 或補值（你可選擇）
data_items <- na.omit(data_items)
# 建立結果儲存列表, minres:最小平方法, ml:主軸抽取法, pa:最大似然法
methods <- c("minres", "ml", "pa")
results_list <- list()
for (m in methods) {
fa_res <- fa(data_items, nfactors = 6, rotate = "varimax", fm = m)
loadings <- as.data.frame(unclass(fa_res$loadings))
loadings$max <- colnames(loadings)[apply(abs(loadings), 1, which.max)]
item_table <- table(loadings$max)
metrics <- data.frame(
method = m,
RMSEA = fa_res$RMSEA[1],
TLI = fa_res$TLI,
RMSR = fa_res$rms
)
results_list[[m]] <- list(metrics = metrics, items = loadings)
}
# PCA 額外處理
pca_res <- principal(data_items, nfactors = 6, rotate = "varimax")
loadings_pca <- as.data.frame(unclass(pca_res$loadings))
loadings_pca$max <- colnames(loadings_pca)[apply(abs(loadings_pca), 1, which.max)]
metrics_pca <- data.frame(
method = "pca",
RMSEA = NA,
TLI = NA,
RMSR = pca_res$rms
)
results_list[["pca"]] <- list(metrics = metrics_pca, items = loadings_pca)
# 彙整成表格
all_metrics <- do.call(rbind, lapply(results_list, function(x) x$metrics))
all_items <- do.call(rbind, lapply(names(results_list), function(name) {
df <- results_list[[name]]$items
df$method <- name
df$item <- rownames(df)
return(df[, c("item", "max", "method")])
}))
library(tidyr)
item_groups <- pivot_wider(all_items, names_from = method, values_from = max)
colnames(item_groups) <- c("item", "minres_group", "ml_group", "pa_group", "pca_group")
# 輸出查看
print(all_metrics)
print(head(all_items, 10))
install.packages("lavaan")
setwd("C:\\Users\\huann\\OneDrive\\Desktop\\Education Big Data\\原始資料")
library(lavaan)
# 載入資料
data1 <- read.csv("data_1.csv", stringsAsFactors = FALSE)
# 選出題目欄位（v1 ~ v60）
data_items <- data1[, grep("^v[0-9]+$", names(data1))]
# 處理缺值（直接刪除不完整的個案）
data_items <- na.omit(data_items)
# 建立六因子模型語法
model <- '
F1 =~ v1 + v2 + v3 + v4 + v5 + v6 + v7 + v8 + v9 + v10 + v11 + v12 + v13 + v53 + v55
F2 =~ v14 + v15 + v16 + v17 + v18 + v19 + v20
F3 =~ v21 + v22 + v23 + v24 + v25
F4 =~ v26 + v27 + v28 + v29 + v30 + v31
F5 =~ v32 + v33 + v34 + v35 + v36 + v37 + v38 + v39 + v40 + v41 + v42 + v43 + v44
F6 =~ v45 + v46 + v47 + v48 + v49 + v50 + v51 + v52 + v54 + v56 + v57 + v58 + v59 + v60
'
# 執行確認性因素分析（CFA）
fit <- cfa(model_syntax, data = data_items, estimator = "ML")
setwd("C:\\Users\\huann\\OneDrive\\Desktop\\Education Big Data\\原始資料")
library(lavaan)
# 載入資料
data1 <- read.csv("data_1.csv", stringsAsFactors = FALSE)
# 選出題目欄位（v1 ~ v60）
data_items <- data1[, grep("^v[0-9]+$", names(data1))]
# 處理缺值（直接刪除不完整的個案）
data_items <- na.omit(data_items)
# 建立六因子模型語法
model <- '
F1 =~ v1 + v2 + v3 + v4 + v5 + v6 + v7 + v8 + v9 + v10 + v11 + v12 + v13 + v53 + v55
F2 =~ v14 + v15 + v16 + v17 + v18 + v19 + v20
F3 =~ v21 + v22 + v23 + v24 + v25
F4 =~ v26 + v27 + v28 + v29 + v30 + v31
F5 =~ v32 + v33 + v34 + v35 + v36 + v37 + v38 + v39 + v40 + v41 + v42 + v43 + v44
F6 =~ v45 + v46 + v47 + v48 + v49 + v50 + v51 + v52 + v54 + v56 + v57 + v58 + v59 + v60
'
# 執行確認性因素分析（CFA）
fit <- cfa(model, data = data_items, estimator = "ML")
# 顯示適配度指標（包含 CFI）
fitMeasures(fit, c("cfi", "tli", "rmsea", "srmr"))
---
title: "HW6"
---
title: "HW6"
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
install.packages("reticulate")
install.packages("keras")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_virtualenv("r-tensorflow", required = TRUE)
install.packages("tidyverse")
install.packages("neuralnet")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_virtualenv("r-tensorflow", required = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_virtualenv("r-tensorflow", required = TRUE)
virtualenv_create("r-tensorflow")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
virtualenv_create("r-tensorflow")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_virtualenv("r-tensorflow", required = TRUE)
library(tidyverse)
library(neuralnet)
iris <- iris %>% mutate_if(is.character, as.factor)#各50sample
summary(iris)
set.seed(245)
data_rows <- floor(0.80 * nrow(iris))
train_indices <- sample(c(1:nrow(iris)), data_rows)
train_data <- iris[train_indices,]
test_data <- iris[-train_indices,]
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
plot(model,rep = "best")
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
table(test_data$Species, prediction_label)
# 計算 accuracy
check = as.numeric(test_data$Species) == max.col(pred)
accuracy = (sum(check)/nrow(test_data))*100
print(accuracy)
library(keras)
library(tensorflow)
library(keras)
library(zeallot)
# 載入 CIFAR-10 資料集
c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_cifar10()
model %>% evaluate(x_test, y_test)
plot(history)
#Each number on the connections represents a weight, which indicates the influence of that input (or the output from the previous layer) on the neuron in the next layer.
#A large weight (positive or negative) means the feature has a strong impact on the result.
#A small weight, close to zero, means the feature has little to no influence.
#Sepal.Length:→1:-0.56744,→2:4.76723,→3:0.50666,→4:0.2246
#Sepal.Width:→1:-0.92667,→2:3.18663,→3:-0.65289,→4:1.4171
#Petal.Length:→1:0.42128,→2:3.29492,→3:-0.3326,→4:-0.46219
#Petal.Width:→1:3.19982,→2:2.57297,→3:-0.9521,→4:-1.65932
#In the neural network plot from Q1, the importance of each feature can be interpreted by looking at the absolute values of the weights from the input layer to the first hidden layer.
#Among all features, Petal.Width has the highest total weight influence (approximately 8.38), indicating it plays the most critical role in predicting the species. This is followed by Sepal.Width (~6.18) and Sepal.Length (~6.07). Petal.Length shows the lowest total weight (~4.51), suggesting it has the least influence among the four features in this model.
#Therefore, Petal.Width is the most significant feature in terms of weights in the current neural network.
install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
knitr::opts_chunk$set(echo = TRUE)
install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
library(reticulate)
use_virtualenv("r-tensorflow", required = TRUE)
install.packages(c("neuralnet", "keras", "tensorflow"), dependencies = T)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_virtualenv("r-tensorflow", required = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_virtualenv("tensorflow", required = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_virtualenv("r~tensorflow", required = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(keras)
library(tensorflow)
library(tidyverse)
library(neuralnet)
iris <- iris %>% mutate_if(is.character, as.factor)#各50sample
summary(iris)
set.seed(245)
data_rows <- floor(0.80 * nrow(iris))
train_indices <- sample(c(1:nrow(iris)), data_rows)
train_data <- iris[train_indices,]
test_data <- iris[-train_indices,]
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
plot(model,rep = "best")
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
table(test_data$Species, prediction_label)
# 計算 accuracy
check = as.numeric(test_data$Species) == max.col(pred)
accuracy = (sum(check)/nrow(test_data))*100
print(accuracy)
library(keras)
library(tensorflow)
library(keras)
library(zeallot)
# 載入 CIFAR-10 資料集
c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_cifar10()
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(keras)
library(tensorflow)
library(reticulate)
use_python("C:/Users/huann/AppData/Local/Programs/Python/Python311/python.exe", required = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(keras)
library(tensorflow)
library(reticulate)
use_python("C://Users//huann//AppData//Local//Programs//Python//Python311//python.exe", required = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(keras)
library(tensorflow)
library(reticulate)
use_python("C://Users//huann//AppData//Local//Programs//Python//Python311//python.exe", required = TRUE)
get python
Get-Command python
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(keras)
library(tensorflow)
library(reticulate)
py_discover_config()
library(keras)
library(tensorflow)
library(keras)
library(zeallot)
# 載入 CIFAR-10 資料集
c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_cifar10()
model %>% evaluate(x_test, y_test)
#The evaluation results are:
#Loss: 0.648
#Accuracy: 0.777
#Loss measures the difference between the predicted values and the true labels. A lower loss indicates better model performance.
#Accuracy represents the percentage of correct predictions. Here, an accuracy of 77.7% means the model correctly classified about 77.7% of the test images.
#These two metrics help us understand how well the model performs. In this case, the model shows good learning capability and generalization.
plot(history)
library(keras)
library(tensorflow)
library(zeallot)
# 檢查是否有安裝 TensorFlow，沒有的話自動安裝（可避免錯誤）
if (!tensorflow::tf_version()) {
install_keras()  # 安裝 Python + TensorFlow
}
library(tm)
install.packages("tm")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(keras)
library(tensorflow)
library(reticulate)
py_discover_config()
library(tm)
install.packages("tm")
# 第四題：繪製文字直方圖與文字雲
library(tm)
library(SnowballC)
library(RColorBrewer)
install.packages("SnowballC")
# 第四題：繪製文字直方圖與文字雲
library(tm)
library(SnowballC)
library(wordcloud)
install.packages("wordcloud")
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
# 建立文字資料
texts <- c("Text mining is the process of deriving high-quality information from text.",
"It involves structuring the input text, deriving patterns within the structured data.",
"Text mining is closely related to natural language processing and machine learning.",
"Typical text mining tasks include text categorization, sentiment analysis, and document clustering.")
# 建立 corpus 並前處理
docs <- Corpus(VectorSource(texts))
docs <- tm_map(docs, content_transformer(tolower))     # 全部小寫
docs <- tm_map(docs, removePunctuation)                # 移除標點
docs <- tm_map(docs, removeNumbers)                    # 移除數字
docs <- tm_map(docs, removeWords, stopwords("en"))     # 移除英文停用詞
docs <- tm_map(docs, stripWhitespace)                  # 移除多餘空白
# 建立詞彙矩陣
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
word_freqs <- sort(rowSums(m), decreasing = TRUE)
word_data <- data.frame(word = names(word_freqs), freq = word_freqs)
# 繪製文字雲
set.seed(1234)
wordcloud(words = word_data$word, freq = word_data$freq,
min.freq = 1, max.words = 100,
random.order = FALSE, colors = brewer.pal(8, "Dark2"))
# 繪製文字頻率直方圖
library(ggplot2)
top_words <- head(word_data, 10)
ggplot(top_words, aes(x = reorder(word, freq), y = freq)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Top 10 Frequent Words", x = "Words", y = "Frequency")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(neuralnet)
iris <- iris %>% mutate_if(is.character, as.factor)#各50sample
summary(iris)
set.seed(245)
data_rows <- floor(0.80 * nrow(iris))
train_indices <- sample(c(1:nrow(iris)), data_rows)
train_data <- iris[train_indices,]
test_data <- iris[-train_indices,]
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
plot(model,rep = "best")
#Each number on the connections represents a weight, which indicates the influence of that input (or the output from the previous layer) on the neuron in the next layer.
#A large weight (positive or negative) means the feature has a strong impact on the result.
#A small weight, close to zero, means the feature has little to no influence.
#Sepal.Length:→1:-0.56744,→2:4.76723,→3:0.50666,→4:0.2246
#Sepal.Width:→1:-0.92667,→2:3.18663,→3:-0.65289,→4:1.4171
#Petal.Length:→1:0.42128,→2:3.29492,→3:-0.3326,→4:-0.46219
#Petal.Width:→1:3.19982,→2:2.57297,→3:-0.9521,→4:-1.65932
#In the neural network plot from Q1, the importance of each feature can be interpreted by looking at the absolute values of the weights from the input layer to the first hidden layer.
#Among all features, Petal.Width has the highest total weight influence (approximately 8.38), indicating it plays the most critical role in predicting the species. This is followed by Sepal.Width (~6.18) and Sepal.Length (~6.07). Petal.Length shows the lowest total weight (~4.51), suggesting it has the least influence among the four features in this model.
#Therefore, Petal.Width is the most significant feature in terms of weights in the current neural network.
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
table(test_data$Species, prediction_label)
# 計算 accuracy
check = as.numeric(test_data$Species) == max.col(pred)
accuracy = (sum(check)/nrow(test_data))*100
print(accuracy)
```
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
table(test_data$Species, prediction_label)
# 計算 accuracy
check = as.numeric(test_data$Species) == max.col(pred)
accuracy = (sum(check)/nrow(test_data))*100
print(accuracy)
library(keras)
install_keras()
#The CNN model was trained on the CIFAR-10 dataset for 10 epochs.
#During training, both the training and validation accuracy increased steadily.
#The model was able to learn meaningful features from the image data.
#No obvious overfitting was observed due to regularization techniques like dropout and max pooling.
#The architecture with multiple convolutional layers and a dense layer gave good performance on the classification task.
model %>% evaluate(x_test, y_test)
#The evaluation results are:
#Loss: 0.695
#Accuracy: 0.761
#Loss measures the difference between the predicted values and the true labels. A lower loss indicates better model performance.
#Accuracy represents the percentage of correct predictions. Here, an accuracy of 76.1% means the model correctly classified about 76.1% of the test images.
#These two metrics help us understand how well the model performs. In this case, the model shows good learning capability and generalization.
plot(history)
library(keras)
install_keras()
